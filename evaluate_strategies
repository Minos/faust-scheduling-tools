#!/usr/bin/env python

from dataclasses import dataclass
import itertools

import argparse
import csv
import os
import random
from glob import glob
from prettytable import PrettyTable

import matplotlib.pyplot as plt
import numpy as np
import scipy as sp
import sklearn


# Superscalar vector size
scaling_factor = 4

deep_first = "0"
breadth_first = "1"
interleaved = "2"
reverse_breadth_first = "3"
custom = "4"

clang = "clang++"
gcc = "g++"
native = "native"
generic = "generic"

context_switches = "context-switches:u"
cpu_migrations = "cpu-migrations:u"
page_faults = "page-faults:u"
instructions = "instructions:u"
cycles = "cycles:u"
branches = "branches:u"
branch_misses = "branch-misses:u"
l1_dcache_loads = "L1-dcache-loads:u"
l1_dcache_load_misses = "L1-dcache-load-misses:u"
llc_loads = "LLC-loads:u"
llc_load_misses = "LLC-load-misses:u"
l1_icache_load_misses = "L1-icache-load-misses:u"
dtlb_loads = "dTLB-loads:u"
dtlb_load_misses = "dTLB-load-misses:u"
itlb_loads = "iTLB-loads:u"
itlb_load_misses = "iTLB-load-misses:u"
cycle_activity_stalls_total = "cycle_activity.stalls_total:u"
cycle_activity_cycles_l3_miss = "cycle_activity.cycles_l3_miss:u"
cycle_activity_stalls_l3_miss = "cycle_activity.stalls_l3_miss:u"
cycle_activity_cycles_l1d_miss = "cycle_activity.cycles_l1d_miss:u"
cycle_activity_cycles_l2_miss = "cycle_activity.cycles_l2_miss:u"
cycle_activity_cycles_mem_any = "cycle_activity.cycles_mem_any:u"
cycle_activity_stalls_l1d_miss = "cycle_activity.stalls_l1d_miss:u"
cycle_activity_stalls_l2_miss = "cycle_activity.stalls_l2_miss:u"
cycle_activity_stalls_mem_any = "cycle_activity.stalls_mem_any:u"

l1_dcache_load_miss_rate = "L1-dcache-load-miss-rate"
llc_load_miss_rate = "LLC-load-miss-rate"
dtlb_load_miss_rate = "dTLB-load-miss-rate"
itlb_load_miss_rate = "iTLB-load-miss-rate"
branch_miss_rate = "branch-miss-rate"
instructions_per_cycle = "instructions-per-cycle"
instructions_and_stalls = "instructions-and-stalls"
cycle_activity_stalls_other = "stalls_other"

STRATEGY_LABELS = {
    deep_first: 'deep-first',
    breadth_first: 'breadth-first',
    interleaved: 'interleaved',
    reverse_breadth_first: 'reverse_breadth_first',
    custom: 'custom',
}

STRATEGY_LABELS_SHORT = {
    deep_first: 'DF',
    breadth_first: 'BF',
    interleaved: 'I',
    reverse_breadth_first: 'RBF',
    custom: 'CUS',
}

COMPILER_LABELS = {
    clang: 'clang',
    gcc: 'gcc',
}

FLAVOR_LABELS = {
    native: 'native',
    generic: 'generic',
}

STRATEGIES = [deep_first, breadth_first, interleaved, reverse_breadth_first]
COMPILERS = [clang, gcc]
FLAVORS = [native, generic]
EVENTS = [
    # context_switches,
    # cpu_migrations,
    # page_faults,
    instructions,
    # cycles,
    # branches,
    # branch_misses,
    # l1_dcache_loads,
    # l1_dcache_load_misses,
    # llc_loads,
    # llc_load_misses,
    # l1_icache_load_misses,
    # dtlb_loads,
    # dtlb_load_misses,
    # itlb_loads,
    # itlb_load_misses,
    # cycle_activity_stalls_total,
    # cycle_activity_cycles_l3_miss,
    # cycle_activity_stalls_l3_miss,
    # cycle_activity_cycles_l1d_miss,
    # cycle_activity_cycles_l2_miss,
    # cycle_activity_cycles_mem_any,
    # cycle_activity_stalls_l1d_miss,
    # cycle_activity_stalls_l2_miss,
    cycle_activity_stalls_mem_any,
]
MEASURES = [
    # l1_dcache_load_miss_rate,
    # llc_load_miss_rate,
    # dtlb_load_miss_rate,
    # itlb_load_miss_rate,
    # branch_miss_rate,
    # instructions_per_cycle,
    # instructions_and_stalls,
    cycle_activity_stalls_other,
]
KEYS = EVENTS + MEASURES


@dataclass
class Run:
    strategy: str
    compiler: str
    flavor: str

    min_time: float = 0
    avg_time: float = 0

    task_clock_ms: float = 0.0
    measures = {}

    def characteristics(self) -> str:
        return f"ss{self.strategy}_{self.compiler}_{self.flavor}"


@dataclass
class Program:
    name: str
    runs: [Run]


def main():
    parser = argparse.ArgumentParser(
        prog="Evaluate Strategies",
        description="Evaluate scheduling strategies run by run_strategies",
    )

    parser.add_argument("path", help="DSP program or directory")
    parser.add_argument("-r", "--run", help="Run number", default=2)
    parser.add_argument("-p", "--plot", help="Plot measures", action='store_true')
    parser.add_argument("-o", "--output", help="Output plot to file", default=None)

    args = parser.parse_args()
    path, ext = os.path.splitext(args.path)
    run = args.run

    plt.style.use('./report.mplstyle')
    # When outputing to png format, we need a higher DPI.
    if args.output:
        plt.rcParams['figure.dpi'] = 512

    if ext == ".dsp" or ext == ".bench":
        directory, program_name = os.path.split(path)
        program = parse_program(directory, program_name, run)
        if args.plot:
            plot_stalls(program, args.output)
        else:
            print_details(program)
    else:
        files = glob("*.dsp", root_dir=path)
        program_names = [os.path.splitext(f)[0] for f in files]
        programs = [parse_program(path, name, run) for name in program_names]
        print_linear_regression(programs)


def plot_linear_regression(reg, program):
    ...


def print_linear_regression(programs: [Program]):
    rate = 1
    training_size = int(len(programs) * rate)
    random.shuffle(programs)
    training = programs[:training_size]

    if training_size < len(programs):
        testing = programs[training_size:]
    else:
        testing = training

    reg = linear_regression(training)
    weights = reg.coef_
    bias = reg.intercept_

    for program in testing:
        print(f'\033[1m{program.name}\033[0m')
        print_cycles(program.runs, color=92)
        print_cycles_predictions(program, weights, bias, color=96)
        print()

    testing_cycles = np.concat([collect_measures(p, cycles) for p in testing])
    testing_data = np.concat([collect_data(p).T for p in testing])
    print(f'Regression score: {reg.score(testing_data, testing_cycles)}')

    print(f'cycles = {int(bias*1e-6)} M')
    for w, k in zip(weights, KEYS):
        if w < 0:
            print(f'       - {-w:.2f} * {k}')
        else:
            print(f'       + {w:.2f} * {k}')


def linear_regression(programs: [Program]):
    training_cycles = np.concat([collect_measures(p, cycles) for p in programs])
    training_data = np.concat([collect_data(p).T for p in programs])

    reg = sklearn.linear_model.LinearRegression(fit_intercept=False)
    reg.fit(training_data, training_cycles)

    return reg


def print_time_predictions(program: Program, weights, bias, *, color=39):
    print_values(program.runs,
                 lambda r: linear_prediction(r, weights, bias),
                 lambda v: f'{v:.04f}ms',
                 "predicted time",
                 color=color)


def print_cycles_predictions(program: Program, weights, bias, *, color=39):
    print_values(program.runs,
                 lambda r: linear_prediction(r, weights, bias),
                 lambda v: f'{int(v*1e-6)} M',
                 "predicted cycles",
                 color=color)


def linear_prediction(run: Run, weights, bias):
    return sum([run.measures[k] * weights[i] for i, k in enumerate(KEYS)]) + bias


def print_details(program: Program):
    times = collect_times(program)
    data = collect_data(program)

    correlations = [(float(sp.stats.pearsonr(data[i], times).statistic), k)
                    for i, k in enumerate(KEYS)]
    correlations = list(reversed(sorted(correlations, key=lambda c: abs(c[0]))))

    print_times(program.runs, color=92)
    print_measures(program.runs, cycles, color=93)
    for c in correlations:
        print(f'\n\033[1m{c[1]}: {c[0]}\033[0m')
        print_measures(program.runs, c[1], color=96)


def plot_stalls(program: Program, output_file=None):
    fig, ax = plt.subplots(figsize=(6, 4))

    nticks = len(COMPILERS) * len(FLAVORS)
    y = np.arange(nticks)

    height = 1 / (len(STRATEGIES) + 1)
    thickness = 0.8
    thickness_inside = thickness * 1

    variants = sorted(itertools.product(COMPILERS, FLAVORS))

    for i, strategy in enumerate(STRATEGIES):
        offset = height * i
        runs = [run for run in program.runs if run.strategy == strategy]
        runs = sorted(runs, key=lambda r: (r.compiler, r.flavor))

        left = np.zeros(4)

        instr = [r.measures[instructions] / scaling_factor for r in runs]
        ax.barh(y + offset, instr, height * thickness_inside,
                color='xkcd:burnt orange',
                label='instr/4' if i == 1 else None)
        left += instr

        st_m = [r.measures[cycle_activity_stalls_mem_any] for r in runs]
        ax.barh(y + offset, st_m, height * thickness_inside,
                left=left, color='xkcd:purple',
                label='stall (mem)' if i == 1 else None)
        left += st_m

        st_o = [r.measures[cycle_activity_stalls_other] for r in runs]
        ax.barh(y + offset, st_o, height * thickness_inside,
                left=left, color='xkcd:light purple',
                label='stall (other)' if i == 1 else None)

        ax.barh(y + offset, [r.measures[cycles] for r in runs],
                height * thickness,
                fill=False, linewidth=1,
                label='cycles' if i == 0 else None, edgecolor='black')

        rects = ax.barh(y + offset + 0.05 * height, [0] * len(runs))
        labels = [STRATEGY_LABELS_SHORT[strategy]] * len(runs)
        ax.bar_label(rects, labels=labels, padding=2, fontsize=6, color='white')

    ax.set_title(f'Instructions et cycles d’attente : {program.name}')
    ax.set_ylabel('Variante')
    yticks = [f'{COMPILER_LABELS[c]} ({FLAVOR_LABELS[f]})' for c, f in variants]
    ax.set_yticks(y + height * (len(STRATEGIES) / 2 - 0.5), yticks)
    ax.invert_yaxis()
    ax.legend(loc='upper left', ncols=4)

    if output_file:
        plt.savefig(output_file, bbox_inches='tight')
    else:
        plt.show()


def print_times(runs: [Run], *, color=39):
    print_values(runs,
                 lambda r: r.avg_time,
                 lambda v: f"{v:.04f}ms",
                 "avg time",
                 color=color)


def print_cycles(runs: [Run], *, color=39):
    print_values(runs,
                 lambda r: r.measures[cycles],
                 lambda v: f"{int(v*1e-6)} M",
                 "cycles",
                 color=color)


def print_measures(runs: [Run], m: str, *, color=39):
    def printer(v):
        if m.endswith("-rate"):
            return f'{v*100:.04f}%' if abs(v) > 1e-3 else f'{v:.2e}'
        elif m.endswith("-per-cycle"):
            return f'{v:.02f}'
        elif v > 1e6:
            return f'{int(v/1000000)} M'
        else:
            return f'{round(v)}'
    print_values(runs, lambda r: r.measures[m], printer, m, color=color)


def print_values(runs: [Run], key, formatter, title, *, color=39):
    table = PrettyTable()
    table.field_names = [title] + STRATEGIES
    table.align = 'r'
    table.align[title] = 'l'
    for compiler in COMPILERS:
        for flavor in FLAVORS:
            table.add_row(
                [f"{compiler} {flavor}"]
                + [formatter(key(r)) for r in runs
                   if r.compiler == compiler and r.flavor == flavor]
            )
    table.add_row(["average"] + [
        formatter(sum([key(r) for r in runs
                       if r.strategy == s]) / len(STRATEGIES))
        for s in STRATEGIES])
    print(f'\033[{color}m{table}\033[0m')


def collect_times(program: Program) -> np.array:
    return np.asarray([run.avg_time for run in program.runs])


def collect_data(program: Program) -> np.array:
    return np.asarray([collect_measures(program, k) for k in KEYS])


def collect_measures(program: Program, m: str) -> np.array:
    return np.asarray([run.measures[m] for run in program.runs])


def parse_run(directory, program_name, strategy, compiler, flavor, run_number) -> Run:
    csv_path = (
        f"{directory}/{program_name}.bench/"
        f"{program_name}_ss{strategy}_{compiler}_{flavor}.r{run_number}.csv"
    )
    run = Run(strategy, compiler, flavor)
    run.measures = {}
    min_times = []
    avg_times = []
    with open(csv_path, "r") as file:
        reader = csv.reader(file, delimiter=";")
        for row in reader:
            name = row[2]
            measure = row[0]
            match name:
                case "minimum":
                    min_times.append(float(measure))
                    avg_times.append(float(row[3]))
                case "task-clock:u":
                    run.task_clock_ms = float(measure.replace(",", "."))
                case _:
                    run.measures[name] = int(measure)

    run.min_time = min(min_times)
    run.avg_time = sum(avg_times) / len(avg_times)

    run.measures[instructions_per_cycle] = (
        run.measures[instructions] / run.measures[cycles]
    )
    run.measures[cycle_activity_stalls_other] = (
        run.measures[cycle_activity_stalls_total]
        - run.measures[cycle_activity_stalls_mem_any]
    )

    return run


def parse_program(directory, program_name, run_number) -> Program:
    runs = []
    for strategy in STRATEGIES:
        for compiler in COMPILERS:
            for flavor in FLAVORS:
                r = parse_run(directory, program_name, strategy, compiler,
                              flavor, run_number)
                runs += [r]
    return Program(program_name, runs)


if __name__ == "__main__":
    main()
